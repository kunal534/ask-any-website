# ğŸš€ Next.js RAG Chatbot (Mistral AI)  

A **Retrieval-Augmented Generation (RAG) Chatbot** built with **Next.js**, **LangChain.js**, **Redis**, and **Mistral AI**.  
This chatbot enhances responses by retrieving relevant contextual data before generating answers.  


Publication link : [Publication](https://app.readytensor.ai/publications/ciphor-bot-rag-based-web-chat-with-llama-and-redis-retention-ElCDzXvDFNMs)
---

## ğŸ“‚ Project Structure  

```plaintext
ğŸ“ Chat_bot
â”‚-- ğŸ“‚ src
â”‚   â”œâ”€â”€ ğŸ“‚ app
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ [...url]     # Dynamic route for chat sessions
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ api          # API routes
â”‚   â”‚   â”œâ”€â”€ ğŸ“œ layout.tsx
â”‚   â”‚   â”œâ”€â”€ ğŸ“œ page.tsx
â”‚   â”œâ”€â”€ ğŸ“‚ components       # Reusable React components
â”‚   â”œâ”€â”€ ğŸ“‚ lib              # Utility functions (RAG, Redis)
â”‚   â”œâ”€â”€ ğŸ“‚ styles           # Styling (CSS, Tailwind, etc.)
â”‚-- .gitignore
â”‚-- package.json
â”‚-- next.config.js
â”‚-- README.md

```
## âš™ï¸ Installation & Setup  

### 1ï¸âƒ£ Clone the repository  

``` sh
git clone https://github.com/kunal534/Chat_bot.git 
cd YOUR_REPO
```

### 2ï¸âƒ£ Install dependencies  
```sh
npm install
```

### 3ï¸âƒ£ Set up environment variables  
Create a `.env.local` file and add:  
```env
MISTRAL_API_KEY=your_mistral_api_key
REDIS_URL=your_redis_url
NEXT_PUBLIC_API_BASE_URL=http://localhost:3000/api
```

### 4ï¸âƒ£ Run the development server  
```sh
npm run dev
```
Your chatbot should now be running at **http://localhost:3000** ğŸ‰  

---

## ğŸ› ï¸ Tech Stack  

- **Frontend:** Next.js, React  
- **Backend:** Next.js API routes  
- **AI Model:** Mistral AI for response generation
- **Database:** Redis for caching and session management
- **Retrieval Layer:** LangChain.js (RAG pipeline)

---

## ğŸ”§ Features  

âœ… Supports RAG-based responses  
âœ… Stores chat history in Redis  
âœ… Handles multi-session conversations  
âœ… Supports dynamic URL-based contexts  
âœ… Easy to deploy on Vercel or Railway  

---

## ğŸš€ Deployment  

### Deploy to Vercel  
```sh
vercel
```

## Future Scope

### Document Content Restriction Handling:

```Currently, the chatbot cannot process files where content extraction is blocked due to:
Digital Rights Management (DRM)
Content Security Policy (CSP)
Other access-control restrictions
In such cases, the RAG pipeline cannot generate embeddings from the content, which limits contextual accuracy.
```

### Potential Enhancements:
```
Integrating OCR-based content extraction for protected documents (where legally permissible)
Expanding parsers to handle non-standard file formats with embedded restrictions
Support for proxy retrieval through secure, authenticated sessions
```
